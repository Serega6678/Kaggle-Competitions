{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKT3PCanbwdi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display, HTML\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import scipy.stats as sps\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfqWad8bb8pG"
   },
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ru-a0tPfcWEr"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv', index_col='id')\n",
    "test = pd.read_csv('./test.csv', index_col='id')\n",
    "train['timestamp'] = train['timestamp'].apply(pd.to_datetime)\n",
    "test['timestamp'] = test['timestamp'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = train._get_numeric_data().columns\n",
    "categorical_features = list(set(train.columns) - set(numeric_features))\n",
    "categorical_features.remove('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ZJ2nsw2fEca"
   },
   "outputs": [],
   "source": [
    "def num_houses_with_bigger_column_value (column_name, value):\n",
    "    return len(train[train[column_name] > value].index)\n",
    "\n",
    "def num_houses_with_less_column_value (column_name, value):\n",
    "    return len(train[train[column_name] < value].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juUN92fJn_eb"
   },
   "outputs": [],
   "source": [
    "def plot_feature_kde(column_name, min_value, max_value):\n",
    "    data = train[column_name]\n",
    "    data = data.where(data.notnull(), axis=0)\n",
    "    data = data[(min_value <= data) & (data <= max_value)]\n",
    "    ax = sns.kdeplot(data=data, shade=True)\n",
    "    ax.set(xlabel= column_name, ylabel='density')\n",
    "\n",
    "def plot_regplot(column_name1, column_name2, col1_min, col1_max, col2_min, col2_max, alpha=0.1):\n",
    "    reg_plot_data = train[[column_name1, column_name2]]\n",
    "    reg_plot_data = reg_plot_data[(col1_min <= train[column_name1]) & (train[column_name1] <= col1_max) \\\n",
    "                                & (col2_min <= train[column_name2]) & (train[column_name2] <= col2_max)]\n",
    "    sns.regplot(x=reg_plot_data[column_name1], y=reg_plot_data[column_name2], \\\n",
    "              scatter_kws={'alpha':alpha})\n",
    "\n",
    "def plot_features_jointplot(column_name1, column_name2, col1_min, col1_max, \\\n",
    "                            col2_min, col2_max, alpha=0.1):\n",
    "    data = train.loc[:, [column_name1, column_name2]]\n",
    "    data = data[data.notnull().all(axis=1)]\n",
    "    data = data[(col1_min <= data[column_name1]) & (data[column_name1] <= col1_max) \\\n",
    "              & (col2_min <= data[column_name2]) & (data[column_name2] <= col2_max)]\n",
    "    sns.jointplot(column_name1, column_name2, data=data, kind=\"kde\", space=0, color=\"b\", \\\n",
    "                scatter_kws={'alpha':alpha})\n",
    "\n",
    "def plot_lmplot(column_name1, column_name2, hue, col1_min, col1_max, \\\n",
    "                            col2_min, col2_max, alpha=0.1):\n",
    "    data = train.loc[:, [column_name1, column_name2, hue]]\n",
    "    data=data[data.notnull().all(axis=1)]\n",
    "    data = data[(col1_min <= data[column_name1]) & (data[column_name1] <= col1_max) \\\n",
    "              & (col2_min <= data[column_name2]) & (data[column_name2] <= col2_max)]\n",
    "    sns.lmplot(x=column_name1, y=column_name2, hue=hue, data=data, scatter_kws={'alpha':alpha})\n",
    "\n",
    "def plot_distplot(column_name):\n",
    "    sns.distplot(a=train[column_name], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAt7Y7NJl2Yu"
   },
   "outputs": [],
   "source": [
    "my_imputer = SimpleImputer(strategy=\"median\")\n",
    "my_scaler = StandardScaler()\n",
    "my_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "my_label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKoLbuyPl2Yz"
   },
   "outputs": [],
   "source": [
    "missed_features = np.array(['preschool_quota', 'school_quota',\n",
    "       'hospital_beds_raion', 'raion_build_count_with_material_info',\n",
    "       'build_count_block', 'build_count_wood', 'build_count_frame',\n",
    "       'build_count_brick', 'build_count_monolith', 'build_count_panel',\n",
    "       'build_count_foam', 'build_count_slag', 'build_count_mix',\n",
    "       'raion_build_count_with_builddate_info', 'build_count_before_1920',\n",
    "       'build_count_1921-1945', 'build_count_1946-1970',\n",
    "       'build_count_1971-1995', 'build_count_after_1995', 'metro_min_walk',\n",
    "       'metro_km_walk', 'railroad_station_walk_km',\n",
    "       'railroad_station_walk_min', 'ID_railroad_station_walk',\n",
    "       'cafe_sum_500_min_price_avg', 'cafe_sum_500_max_price_avg',\n",
    "       'cafe_avg_price_500', 'cafe_sum_1000_min_price_avg',\n",
    "       'cafe_sum_1000_max_price_avg', 'cafe_avg_price_1000',\n",
    "       'cafe_sum_1500_min_price_avg', 'cafe_sum_1500_max_price_avg',\n",
    "       'cafe_avg_price_1500', 'cafe_sum_2000_min_price_avg',\n",
    "       'cafe_sum_2000_max_price_avg', 'cafe_avg_price_2000',\n",
    "       'cafe_sum_3000_min_price_avg', 'cafe_sum_3000_max_price_avg',\n",
    "       'cafe_avg_price_3000', 'prom_part_5000', 'cafe_sum_5000_min_price_avg',\n",
    "       'cafe_sum_5000_max_price_avg', 'cafe_avg_price_5000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtV-68dn3Vag"
   },
   "outputs": [],
   "source": [
    "def change_life_sq (row):\n",
    "    if row['life_sq'] > 100 and row['life_sq/full_sq'] > 1 / 0.67:\n",
    "        return row['full_sq']\n",
    "    elif row['life_sq/full_sq'] > 1 / 0.67:\n",
    "        return row['life_sq'] - row['full_sq']\n",
    "    elif row['full_sq'] < row['life_sq']:\n",
    "        return row['full_sq']\n",
    "    return row['life_sq']\n",
    "\n",
    "def change_full_sq (row):\n",
    "    if row['life_sq'] > 100 and row['life_sq/full_sq'] > 1 / 0.67:\n",
    "        return row['full_sq']\n",
    "    elif row['life_sq/full_sq'] > 1.3:\n",
    "        return row['life_sq']\n",
    "    elif row['full_sq'] < row['life_sq']:\n",
    "        return row['life_sq']\n",
    "    return row['full_sq']\n",
    "\n",
    "def account_kitch_sq (row):\n",
    "    if row['kitch_sq'] >= 0 and row['kitch_sq'] < row['full_sq_help']:\n",
    "        return row['full_sq_help'] - row['kitch_sq']\n",
    "    return row['life_sq_help']\n",
    "\n",
    "def fill_max_floor (row):\n",
    "    if not pd.isnull(row['build_year']) and row['build_year'] < 1930:\n",
    "        return 2\n",
    "    if not pd.isnull(row['max_floor']):\n",
    "        return row['max_floor']\n",
    "    if not pd.isnull(row['build_year']) and row['build_year'] > 0:\n",
    "        dict_year = (row['build_year'] // 10) * 10\n",
    "        if dict_year < 1930:\n",
    "            return 2\n",
    "        else:\n",
    "            return d[dict_year]\n",
    "    if not pd.isna(row['floor']):\n",
    "        if row['floor'] > 16:\n",
    "            return row['floor']\n",
    "        if row['floor'] > 12:\n",
    "            return 16\n",
    "        if row['floor'] > 8:\n",
    "            return 12\n",
    "    return 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Let's modify the pipeline to suppord categorical features transformation & feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pipeline(data_recieved, is_train=True, numeric_features=numeric_features, \\\n",
    "                    categorical_features=categorical_features):\n",
    "    data = data_recieved.copy()\n",
    "    \n",
    "    if is_train:\n",
    "        data.drop(data[data['full_sq'] > 1000].index, inplace=True)\n",
    "        data.drop(data[data['build_year'] > 2018].index, inplace=True)\n",
    "        data.drop(data[(data['full_sq'] == 0) & (data['life_sq'] == 0) & (data['kitch_sq'] == 0)].index, \\\n",
    "                  inplace=True)\n",
    "\n",
    "    mean_division_value = 0.67\n",
    "    \n",
    "    data['life_sq/full_sq'] = data['life_sq'] / (data['full_sq'] + 1)\n",
    "    data['life_sq/full_sq'].mask(np.isinf(data['life_sq/full_sq']), inplace=True)\n",
    "    data['life_sq/full_sq'].fillna(mean_division_value, inplace=True)\n",
    "\n",
    "    data.loc[data['life_sq'] > 200, 'life_sq'] = \\\n",
    "                                data[data['life_sq'] > 200].apply(lambda x: \\\n",
    "                                x['full_sq'] - x['kitch_sq'] if x['kitch_sq'] >= 0 else x['full_sq'], axis=1)\n",
    "\n",
    "    mean_value = data['life_sq/full_sq'].mean()\n",
    "    data['life_sq'] = data.apply(lambda x: x['life_sq'] if not pd.isnull(x['life_sq']) \\\n",
    "                                   else x['full_sq'] * mean_value, axis=1)\n",
    "    \n",
    "    data_help = data[['full_sq', 'life_sq', 'kitch_sq', 'life_sq/full_sq']].copy()\n",
    "    data_help['life_sq_help'] = data_help.apply(change_life_sq, axis=1)\n",
    "    data_help['full_sq_help'] = data_help.apply(change_full_sq, axis=1)\n",
    "    data_help['life_sq_help'] = data_help.apply(account_kitch_sq, axis=1)\n",
    "    data_help['life_sq_help'] = data_help.apply(lambda x: x['life_sq_help'] \\\n",
    "                            if not pd.isnull(x['life_sq_help']) else x['full_sq_help'] * mean_value, axis=1)\n",
    "    data[['full_sq', 'life_sq']] = data_help[['full_sq_help', 'life_sq_help']]\n",
    "    data.loc[data['life_sq/full_sq'] > 0.9, 'life_sq'] = \\\n",
    "                    data.loc[data['life_sq/full_sq'] > 0.9].apply(lambda x: x['full_sq'] * mean_value, axis=1)\n",
    "    \n",
    "    data.loc[:, 'life_sq'] = data.apply(lambda x: math.ceil(x['life_sq']), axis=1)\n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['kitch_sq'] = data.apply(lambda x: x['full_sq'] - x['life_sq'] , axis = 1)\n",
    "    data['life_sq/kitch_sq'] = (data['life_sq']) / (data['kitch_sq'] + 1)\n",
    "    \n",
    "    data_help = data[['kitch_sq', 'life_sq', 'full_sq', 'life_sq/kitch_sq', 'num_room']].copy()\n",
    "    data_help['life_sq_help'] = data_help.apply(lambda x: x['kitch_sq'] \\\n",
    "                                    if x['life_sq/kitch_sq'] < x['num_room'] * 1.3 else x['life_sq'], axis=1)\n",
    "    data_help['kitch_sq_help'] = data_help.apply(lambda x: x['life_sq'] \\\n",
    "                                    if x['life_sq/kitch_sq'] < x['num_room'] * 1.3 else x['kitch_sq'], axis=1)\n",
    "    data[['life_sq', 'kitch_sq']]= data_help[['life_sq_help', 'kitch_sq_help']]\n",
    "    \n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['life_sq/kitch_sq'] = (data['life_sq'] + 1) / (data['kitch_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['kitch_sq/life_sq'] = 1 / data['life_sq/kitch_sq']\n",
    "    \n",
    "    data.rename(columns={'kitch_sq' : 'other_sq'}, inplace=True)\n",
    "    \n",
    "    numeric_features = [feature if feature != 'kitch_sq' else 'other_sq' for feature in numeric_features]\n",
    "    \n",
    "    data.loc[:, 'full_sq'] = data.apply(lambda x: round(x['full_sq']), axis=1)\n",
    "    data.loc[:, 'life_sq'] = data.apply(lambda x: round(x['life_sq']), axis=1)\n",
    "    data.loc[:, 'other_sq'] = data.apply(lambda x: round(x['other_sq']), axis=1)\n",
    "    \n",
    "    data.drop(columns=['life_sq/kitch_sq', 'kitch_sq/life_sq'], inplace=True)\n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['life_sq/other_sq'] = (data['life_sq'] + 1) / (data['other_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['other_sq/life_sq'] = 1 / data['life_sq/other_sq']\n",
    "    \n",
    "    sample_data = data[['life_sq', 'other_sq', 'life_sq/other_sq']].copy()\n",
    "    data.loc[:, 'life_sq'] = sample_data.apply(lambda x: x['life_sq'] if \\\n",
    "                                        x['life_sq/other_sq'] > 0.8 else x['other_sq'], axis=1)\n",
    "    data.loc[:, 'other_sq'] = sample_data.apply(lambda x: x['other_sq'] if \\\n",
    "                                        x['life_sq/other_sq'] > 0.8 else x['life_sq'], axis=1)\n",
    "    \n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['life_sq/other_sq'] = (data['life_sq'] + 1) / (data['other_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['other_sq/life_sq'] = 1 / data['life_sq/other_sq'] \n",
    "    \n",
    "    if is_train:\n",
    "        data.drop(data[data['full_sq'] > 290].index, inplace=True)\n",
    "        data.drop(1030, inplace=True)\n",
    "    \n",
    "    data.loc[:, 'max_floor'] = data.apply(lambda x: x['floor'] \\\n",
    "                                     if x['floor'] > x['max_floor'] else x['max_floor'], axis=1)\n",
    "    data.loc[:, 'max_floor'] = data.apply(fill_max_floor, axis=1)\n",
    "    data.loc[:, 'floor'] = data.apply(lambda x: x['max_floor'] // 2 if pd.isnull(x['floor']) \\\n",
    "                             else x['floor'], axis=1)\n",
    "    data.loc[data['build_year'] < 1860, 'build_year'] = np.nan\n",
    "    \n",
    "    data.loc[:, 'num_room was missing'] = data['num_room'].isnull()\n",
    "    data.loc[data['num_room'].isnull(), 'num_room'] = np.round(data.loc[data['num_room'].isnull(), \\\n",
    "                                                                       'life_sq'] / 23)\n",
    "    data.loc[:, 'material'].fillna(7, inplace=True)\n",
    "    \n",
    "    for feature in missed_features:\n",
    "        data[feature + ' was missing'] = data[feature].isnull()\n",
    "        for area in set(data['sub_area'].values):\n",
    "            if area in set(train['sub_area'].values):\n",
    "                data.loc[(data['sub_area'] == area) & (pd.isnull(data[feature])), feature] = \\\n",
    "                train[(train['sub_area'] == area) & (~pd.isnull(train[feature]))][feature].median()\n",
    "\n",
    "    data.loc[pd.isnull(data['product_type']), 'product_type'] = 'Investment'\n",
    "                \n",
    "    for column_name in data.columns:\n",
    "        data[column_name + ' was missing'] = data[column_name].isnull()\n",
    "    \n",
    "    if is_train:\n",
    "        my_label_encoder.fit(data['sub_area'])\n",
    "    data.loc[:, 'sub_area'] = my_label_encoder.transform(data['sub_area'])\n",
    "    \n",
    "    if is_train:\n",
    "        my_imputer.fit(data.loc[:, numeric_features[: -1]])\n",
    "    data.loc[:, numeric_features[: -1]] = my_imputer.transform(data.loc[:, numeric_features[: -1]])\n",
    "    \n",
    "    if is_train:\n",
    "        my_scaler.fit(data.loc[:, numeric_features[: -1]])\n",
    "    data.loc[:, numeric_features[:-1]] = my_scaler.transform(data.loc[:, numeric_features[: -1]])\n",
    "    \n",
    "    label_features = ['sub_area']\n",
    "    one_hot_features = categorical_features.copy()\n",
    "    \n",
    "    for feature in label_features:\n",
    "        one_hot_features.remove(feature)\n",
    "    \n",
    "    if is_train:\n",
    "        my_hot_encoder.fit(data.loc[:, one_hot_features])\n",
    "    \n",
    "    new_hot_features = pd.DataFrame(my_hot_encoder.transform(data.loc[:, one_hot_features]).toarray())\n",
    "    for column in new_hot_features.columns:\n",
    "        new_hot_features.rename(columns={column : 'One_hot_' + str(column)}, inplace=True)\n",
    "    data[new_hot_features.columns] = new_hot_features.set_index(data.index)\n",
    "    \n",
    "    data.drop(columns=one_hot_features, inplace=True)\n",
    "    \n",
    "    data['month'] = data.apply(lambda x: x['timestamp'].month, axis=1)\n",
    "    data['year'] = data.apply(lambda x: x['timestamp'].year, axis=1)\n",
    "    \n",
    "    data.drop(columns=['timestamp'], inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeCPRgWV5yf9"
   },
   "outputs": [],
   "source": [
    "new_train = custom_pipeline(train)\n",
    "new_test = custom_pipeline(test, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FdBnCnVnl2ZI",
    "outputId": "fe42772d-48f9-4d57-daff-033b48de55bc",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lAhMMUWAl2ZK",
    "outputId": "cf9b5c1c-fec2-422d-a61c-714d095c539f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1tTF_HQl2ap"
   },
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_scorer(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_train['price_doc']\n",
    "new_train.drop(columns=['price_doc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 15\n",
    "\n",
    "grid_params = {\n",
    "    'num_leaves' : sps.randint(20, 51).rvs(size=n_iter),\n",
    "    'learning_rate' : np.linspace(0.005, 0.15, 100),\n",
    "    'n_estimators' : sps.randint(80, 171).rvs(size=n_iter),\n",
    "    'boosting_type' : ['gbdt', 'dart']\n",
    "}\n",
    "\n",
    "scorer = make_scorer(rmsle_scorer, greater_is_better=False)\n",
    "\n",
    "model = LGBMRegressor()\n",
    "time_split = TimeSeriesSplit(n_splits=4)\n",
    "grid = RandomizedSearchCV(model, param_distributions=grid_params, cv=time_split, \\\n",
    "                          scoring=scorer, n_jobs=-1, n_iter=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "ubmSN7FWl2a1",
    "outputId": "95e59374-a7fa-471d-a6bf-d4892fd1b818",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid.fit(new_train, y, eval_metric=rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "d2wsTm8I0nG9",
    "outputId": "7a3ef067-743f-4962-d905-dd07464a91cd"
   },
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think these parameters are great for the model because the model was validated as a time-series thus leading to correct evalutation."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Additional Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
