{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKT3PCanbwdi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display, HTML\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfqWad8bb8pG"
   },
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ru-a0tPfcWEr"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv', index_col='id')\n",
    "test = pd.read_csv('./test.csv', index_col='id')\n",
    "train['timestamp'] = train['timestamp'].apply(pd.to_datetime)\n",
    "test['timestamp'] = test['timestamp'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "TyQeKKFRl2ZZ",
    "outputId": "83814fd1-61c5-46b1-a97b-ae2b9dc946b4"
   },
   "outputs": [],
   "source": [
    "numeric_features = train._get_numeric_data().columns\n",
    "categorical_features = list(set(train.columns) - set(numeric_features))\n",
    "categorical_features.remove('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3fUbdupkzPOO"
   },
   "source": [
    "## &emsp; Data processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAt7Y7NJl2Yu"
   },
   "outputs": [],
   "source": [
    "my_imputer = SimpleImputer(strategy=\"median\")\n",
    "my_scaler = StandardScaler()\n",
    "my_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "my_label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKoLbuyPl2Yz"
   },
   "outputs": [],
   "source": [
    "missed_features = np.array(['preschool_quota', 'school_quota',\n",
    "       'hospital_beds_raion', 'raion_build_count_with_material_info',\n",
    "       'build_count_block', 'build_count_wood', 'build_count_frame',\n",
    "       'build_count_brick', 'build_count_monolith', 'build_count_panel',\n",
    "       'build_count_foam', 'build_count_slag', 'build_count_mix',\n",
    "       'raion_build_count_with_builddate_info', 'build_count_before_1920',\n",
    "       'build_count_1921-1945', 'build_count_1946-1970',\n",
    "       'build_count_1971-1995', 'build_count_after_1995', 'metro_min_walk',\n",
    "       'metro_km_walk', 'railroad_station_walk_km',\n",
    "       'railroad_station_walk_min', 'ID_railroad_station_walk',\n",
    "       'cafe_sum_500_min_price_avg', 'cafe_sum_500_max_price_avg',\n",
    "       'cafe_avg_price_500', 'cafe_sum_1000_min_price_avg',\n",
    "       'cafe_sum_1000_max_price_avg', 'cafe_avg_price_1000',\n",
    "       'cafe_sum_1500_min_price_avg', 'cafe_sum_1500_max_price_avg',\n",
    "       'cafe_avg_price_1500', 'cafe_sum_2000_min_price_avg',\n",
    "       'cafe_sum_2000_max_price_avg', 'cafe_avg_price_2000',\n",
    "       'cafe_sum_3000_min_price_avg', 'cafe_sum_3000_max_price_avg',\n",
    "       'cafe_avg_price_3000', 'prom_part_5000', 'cafe_sum_5000_min_price_avg',\n",
    "       'cafe_sum_5000_max_price_avg', 'cafe_avg_price_5000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_life_sq (row):\n",
    "    if row['life_sq'] > 100 and row['life_sq/full_sq'] > 1 / 0.67:\n",
    "        return row['full_sq']\n",
    "    elif row['life_sq/full_sq'] > 1 / 0.67:\n",
    "        return row['life_sq'] - row['full_sq']\n",
    "    elif row['full_sq'] < row['life_sq']:\n",
    "        return row['full_sq']\n",
    "    return row['life_sq']\n",
    "\n",
    "def change_full_sq (row):\n",
    "    if row['life_sq'] > 100 and row['life_sq/full_sq'] > 1 / 0.67:\n",
    "        return row['full_sq']\n",
    "    elif row['life_sq/full_sq'] > 1.3:\n",
    "        return row['life_sq']\n",
    "    elif row['full_sq'] < row['life_sq']:\n",
    "        return row['life_sq']\n",
    "    return row['full_sq']\n",
    "\n",
    "def account_kitch_sq (row):\n",
    "    if row['kitch_sq'] >= 0 and row['kitch_sq'] < row['full_sq_help']:\n",
    "        return row['full_sq_help'] - row['kitch_sq']\n",
    "    return row['life_sq_help']\n",
    "\n",
    "def fill_max_floor (row):\n",
    "    if not pd.isnull(row['build_year']) and row['build_year'] < 1930:\n",
    "        return 2\n",
    "    if not pd.isnull(row['max_floor']):\n",
    "        return row['max_floor']\n",
    "    if not pd.isnull(row['build_year']) and row['build_year'] > 0:\n",
    "        dict_year = (row['build_year'] // 10) * 10\n",
    "        if dict_year < 1930:\n",
    "            return 2\n",
    "        else:\n",
    "            return d[dict_year]\n",
    "    if not pd.isna(row['floor']):\n",
    "        if row['floor'] > 16:\n",
    "            return row['floor']\n",
    "        if row['floor'] > 12:\n",
    "            return 16\n",
    "        if row['floor'] > 8:\n",
    "            return 12\n",
    "    return 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtV-68dn3Vag"
   },
   "outputs": [],
   "source": [
    "def custom_pipeline(data_recieved, is_train=True, numeric_features=numeric_features, \\\n",
    "                    categorical_features=categorical_features):\n",
    "    data = data_recieved.copy()\n",
    "    \n",
    "    if is_train:\n",
    "        data.drop(data[data['full_sq'] > 1000].index, inplace=True)\n",
    "        data.drop(data[data['build_year'] > 2018].index, inplace=True)\n",
    "        data.drop(data[(data['full_sq'] == 0) & (data['life_sq'] == 0) & (data['kitch_sq'] == 0)].index, \\\n",
    "                  inplace=True)\n",
    "\n",
    "    mean_division_value = 0.67\n",
    "    \n",
    "    data['life_sq/full_sq'] = data['life_sq'] / (data['full_sq'] + 1)\n",
    "    data['life_sq/full_sq'].mask(np.isinf(data['life_sq/full_sq']), inplace=True)\n",
    "    data['life_sq/full_sq'].fillna(mean_division_value, inplace=True)\n",
    "\n",
    "    data.loc[data['life_sq'] > 200, 'life_sq'] = \\\n",
    "                                    data[data['life_sq'] > 200].apply(lambda x: \\\n",
    "                                    x['full_sq'] - x['kitch_sq'] if x['kitch_sq'] >= 0 else x['full_sq'], axis=1)\n",
    "\n",
    "    mean_value = data['life_sq/full_sq'].mean()\n",
    "    data['life_sq'] = data.apply(lambda x: x['life_sq'] if not pd.isnull(x['life_sq']) \\\n",
    "                                   else x['full_sq'] * mean_value, axis=1)\n",
    "    \n",
    "    data_help = data[['full_sq', 'life_sq', 'kitch_sq', 'life_sq/full_sq']].copy()\n",
    "    data_help['life_sq_help'] = data_help.apply(change_life_sq, axis=1)\n",
    "    data_help['full_sq_help'] = data_help.apply(change_full_sq, axis=1)\n",
    "    data_help['life_sq_help'] = data_help.apply(account_kitch_sq, axis=1)\n",
    "    data_help['life_sq_help'] = data_help.apply(lambda x: x['life_sq_help'] \\\n",
    "                                if not pd.isnull(x['life_sq_help']) else x['full_sq_help'] * mean_value, axis=1)\n",
    "    data[['full_sq', 'life_sq']] = data_help[['full_sq_help', 'life_sq_help']]\n",
    "    data.loc[data['life_sq/full_sq'] > 0.9, 'life_sq'] = \\\n",
    "                    data.loc[data['life_sq/full_sq'] > 0.9].apply(lambda x: x['full_sq'] * mean_value, axis=1)\n",
    "    \n",
    "    data.loc[:, 'life_sq'] = data.apply(lambda x: math.ceil(x['life_sq']), axis=1)\n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['kitch_sq'] = data.apply(lambda x: x['full_sq'] - x['life_sq'] , axis = 1)\n",
    "    data['life_sq/kitch_sq'] = (data['life_sq']) / (data['kitch_sq'] + 1)\n",
    "    \n",
    "    data_help = data[['kitch_sq', 'life_sq', 'full_sq', 'life_sq/kitch_sq', 'num_room']].copy()\n",
    "    data_help['life_sq_help'] = data_help.apply(lambda x: x['kitch_sq'] \\\n",
    "                                        if x['life_sq/kitch_sq'] < x['num_room'] * 1.3 else x['life_sq'], axis=1)\n",
    "    data_help['kitch_sq_help'] = data_help.apply(lambda x: x['life_sq'] \\\n",
    "                                        if x['life_sq/kitch_sq'] < x['num_room'] * 1.3 else x['kitch_sq'], axis=1)\n",
    "    data[['life_sq', 'kitch_sq']]= data_help[['life_sq_help', 'kitch_sq_help']]\n",
    "    \n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['life_sq/kitch_sq'] = (data['life_sq'] + 1) / (data['kitch_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['kitch_sq/life_sq'] = 1 / data['life_sq/kitch_sq']\n",
    "    \n",
    "    data.rename(columns={'kitch_sq' : 'other_sq'}, inplace=True)\n",
    "    \n",
    "    numeric_features = [feature if feature != 'kitch_sq' else 'other_sq' for feature in numeric_features]\n",
    "    \n",
    "    data.loc[:, 'full_sq'] = data.apply(lambda x: round(x['full_sq']), axis=1)\n",
    "    data.loc[:, 'life_sq'] = data.apply(lambda x: round(x['life_sq']), axis=1)\n",
    "    data.loc[:, 'other_sq'] = data.apply(lambda x: round(x['other_sq']), axis=1)\n",
    "    \n",
    "    data.drop(columns=['life_sq/kitch_sq', 'kitch_sq/life_sq'], inplace=True)\n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['life_sq/other_sq'] = (data['life_sq'] + 1) / (data['other_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['other_sq/life_sq'] = 1 / data['life_sq/other_sq']\n",
    "    \n",
    "    sample_data = data[['life_sq', 'other_sq', 'life_sq/other_sq']].copy()\n",
    "    data.loc[:, 'life_sq'] = sample_data.apply(lambda x: x['life_sq'] if \\\n",
    "                                        x['life_sq/other_sq'] > 0.8 else x['other_sq'], axis=1)\n",
    "    data.loc[:, 'other_sq'] = sample_data.apply(lambda x: x['other_sq'] if \\\n",
    "                                        x['life_sq/other_sq'] > 0.8 else x['life_sq'], axis=1)\n",
    "    \n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['life_sq/other_sq'] = (data['life_sq'] + 1) / (data['other_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['other_sq/life_sq'] = 1 / data['life_sq/other_sq'] \n",
    "    \n",
    "    if is_train:\n",
    "        data.drop(data[data['full_sq'] > 290].index, inplace=True)\n",
    "        data.drop(1030, inplace=True)\n",
    "    \n",
    "    data.loc[:, 'max_floor'] = data.apply(lambda x: x['floor'] \\\n",
    "                                     if x['floor'] > x['max_floor'] else x['max_floor'], axis=1)\n",
    "    data.loc[:, 'max_floor'] = data.apply(fill_max_floor, axis=1)\n",
    "    data.loc[:, 'floor'] = data.apply(lambda x: x['max_floor'] // 2 if pd.isnull(x['floor']) \\\n",
    "                             else x['floor'], axis=1)\n",
    "    data.loc[data['build_year'] < 1860, 'build_year'] = np.nan\n",
    "    \n",
    "    data.loc[:, 'num_room was missing'] = data['num_room'].isnull()\n",
    "    data.loc[data['num_room'].isnull(), 'num_room'] = np.round(data.loc[data['num_room'].isnull(), \\\n",
    "                                                                       'life_sq'] / 23)\n",
    "    data.loc[:, 'material'].fillna(7, inplace=True)\n",
    "    \n",
    "    for feature in missed_features:\n",
    "        data[feature + ' was missing'] = data[feature].isnull()\n",
    "        for area in set(data['sub_area'].values):\n",
    "            if area in set(train['sub_area'].values):\n",
    "                data.loc[(data['sub_area'] == area) & (pd.isnull(data[feature])), feature] = \\\n",
    "                train[(train['sub_area'] == area) & (~pd.isnull(train[feature]))][feature].median()\n",
    "\n",
    "    data.loc[pd.isnull(data['product_type']), 'product_type'] = 'Investment'\n",
    "                \n",
    "    for column_name in data.columns:\n",
    "        data[column_name + ' was missing'] = data[column_name].isnull()\n",
    "    \n",
    "    if is_train:\n",
    "        my_label_encoder.fit(data['sub_area'])\n",
    "    data.loc[:, 'sub_area'] = my_label_encoder.transform(data['sub_area'])\n",
    "    \n",
    "    if is_train:\n",
    "        my_imputer.fit(data.loc[:, numeric_features[: -1]])\n",
    "    data.loc[:, numeric_features[: -1]] = my_imputer.transform(data.loc[:, numeric_features[: -1]])\n",
    "    \n",
    "    if is_train:\n",
    "        my_scaler.fit(data.loc[:, numeric_features[: -1]])\n",
    "    data.loc[:, numeric_features[:-1]] = my_scaler.transform(data.loc[:, numeric_features[: -1]])\n",
    "    \n",
    "    label_features = ['sub_area']\n",
    "    one_hot_features = categorical_features.copy()\n",
    "    \n",
    "    for feature in label_features:\n",
    "        one_hot_features.remove(feature)\n",
    "    \n",
    "    if is_train:\n",
    "        my_hot_encoder.fit(data.loc[:, one_hot_features])\n",
    "    \n",
    "    new_hot_features = pd.DataFrame(my_hot_encoder.transform(data.loc[:, one_hot_features]).toarray())\n",
    "    for column in new_hot_features.columns:\n",
    "        new_hot_features.rename(columns={column : 'One_hot_' + str(column)}, inplace=True)\n",
    "    data[new_hot_features.columns] = new_hot_features.set_index(data.index)\n",
    "    \n",
    "    data.drop(columns=one_hot_features, inplace=True)\n",
    "    \n",
    "    data['month'] = data.apply(lambda x: x['timestamp'].month, axis=1)\n",
    "    data['year'] = data.apply(lambda x: x['timestamp'].year, axis=1)\n",
    "    \n",
    "    data.drop(columns=['timestamp'], inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeCPRgWV5yf9"
   },
   "outputs": [],
   "source": [
    "new_train = custom_pipeline(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = custom_pipeline(test, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phqhDJiIl2al",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "investment_indexes = train[train['product_type'] == 'Investment'].index\n",
    "investment_indexes = [index for index in investment_indexes if index in new_train.index]\n",
    "owner_occupier_indexes = train[train['product_type'] != 'Investment'].index\n",
    "owner_occupier_indexes = [index for index in owner_occupier_indexes if index in new_train.index]\n",
    "new_train_investment = new_train.loc[investment_indexes, :]\n",
    "new_train_investment_y = new_train_investment['price_doc']\n",
    "new_train_investment.drop(columns=['price_doc'], inplace=True)\n",
    "new_train_owner_occupier = new_train.loc[owner_occupier_indexes, :]\n",
    "new_train_owner_occupier_y = new_train_owner_occupier['price_doc']\n",
    "new_train_owner_occupier.drop(columns=['price_doc'], inplace=True)\n",
    "owner_occupier_indexes = test[test['product_type'] == 'OwnerOccupier'].index\n",
    "investment_indexes = test[test['product_type'] != 'OwnerOccupier'].index\n",
    "new_test_investment = new_test.loc[investment_indexes, :]\n",
    "new_test_owner_occupier = new_test.loc[owner_occupier_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1tTF_HQl2ap"
   },
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePBC_76_l2az"
   },
   "outputs": [],
   "source": [
    "investment_model = LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \\\n",
    "                                 importance_type='split', learning_rate=0.05333333333333333, max_depth=-1, \\\n",
    "                                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, \\\n",
    "                                 n_estimators=170, n_jobs=-1, num_leaves=20, objective=None, random_state=None, \\\n",
    "                                 reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, \\\n",
    "                                 subsample_for_bin=200000, subsample_freq=0)\n",
    "owner_occupier_model = LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \\\n",
    "                                 importance_type='split', learning_rate=0.05333333333333333, max_depth=-1, \\\n",
    "                                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, \\\n",
    "                                 n_estimators=170, n_jobs=-1, num_leaves=20, objective=None, random_state=None, \\\n",
    "                                 reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, \\\n",
    "                                 subsample_for_bin=200000, subsample_freq=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Additional Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
