{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKT3PCanbwdi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display, HTML\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfqWad8bb8pG"
   },
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ru-a0tPfcWEr"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv', index_col='id')\n",
    "test = pd.read_csv('./test.csv', index_col='id')\n",
    "train['timestamp'] = train['timestamp'].apply(pd.to_datetime)\n",
    "test['timestamp'] = test['timestamp'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "TyQeKKFRl2ZZ",
    "outputId": "83814fd1-61c5-46b1-a97b-ae2b9dc946b4"
   },
   "outputs": [],
   "source": [
    "numeric_features = train._get_numeric_data().columns\n",
    "categorical_features = list(set(train.columns) - set(numeric_features))\n",
    "categorical_features.remove('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3fUbdupkzPOO"
   },
   "source": [
    "## &emsp; Data processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAt7Y7NJl2Yu"
   },
   "outputs": [],
   "source": [
    "my_imputer = SimpleImputer(strategy=\"median\")\n",
    "my_scaler = StandardScaler()\n",
    "my_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "my_label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKoLbuyPl2Yz"
   },
   "outputs": [],
   "source": [
    "missed_features = np.array(['preschool_quota', 'school_quota',\n",
    "       'hospital_beds_raion', 'raion_build_count_with_material_info',\n",
    "       'build_count_block', 'build_count_wood', 'build_count_frame',\n",
    "       'build_count_brick', 'build_count_monolith', 'build_count_panel',\n",
    "       'build_count_foam', 'build_count_slag', 'build_count_mix',\n",
    "       'raion_build_count_with_builddate_info', 'build_count_before_1920',\n",
    "       'build_count_1921-1945', 'build_count_1946-1970',\n",
    "       'build_count_1971-1995', 'build_count_after_1995', 'metro_min_walk',\n",
    "       'metro_km_walk', 'railroad_station_walk_km',\n",
    "       'railroad_station_walk_min', 'ID_railroad_station_walk',\n",
    "       'cafe_sum_500_min_price_avg', 'cafe_sum_500_max_price_avg',\n",
    "       'cafe_avg_price_500', 'cafe_sum_1000_min_price_avg',\n",
    "       'cafe_sum_1000_max_price_avg', 'cafe_avg_price_1000',\n",
    "       'cafe_sum_1500_min_price_avg', 'cafe_sum_1500_max_price_avg',\n",
    "       'cafe_avg_price_1500', 'cafe_sum_2000_min_price_avg',\n",
    "       'cafe_sum_2000_max_price_avg', 'cafe_avg_price_2000',\n",
    "       'cafe_sum_3000_min_price_avg', 'cafe_sum_3000_max_price_avg',\n",
    "       'cafe_avg_price_3000', 'prom_part_5000', 'cafe_sum_5000_min_price_avg',\n",
    "       'cafe_sum_5000_max_price_avg', 'cafe_avg_price_5000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_life_sq (row):\n",
    "    if row['life_sq'] > 100 and row['life_sq/full_sq'] > 1 / 0.67:\n",
    "        return row['full_sq']\n",
    "    elif row['life_sq/full_sq'] > 1 / 0.67:\n",
    "        return row['life_sq'] - row['full_sq']\n",
    "    elif row['full_sq'] < row['life_sq']:\n",
    "        return row['full_sq']\n",
    "    return row['life_sq']\n",
    "\n",
    "def change_full_sq (row):\n",
    "    if row['life_sq'] > 100 and row['life_sq/full_sq'] > 1 / 0.67:\n",
    "        return row['full_sq']\n",
    "    elif row['life_sq/full_sq'] > 1.3:\n",
    "        return row['life_sq']\n",
    "    elif row['full_sq'] < row['life_sq']:\n",
    "        return row['life_sq']\n",
    "    return row['full_sq']\n",
    "\n",
    "def account_kitch_sq (row):\n",
    "    if row['kitch_sq'] >= 0 and row['kitch_sq'] < row['full_sq_help']:\n",
    "        return row['full_sq_help'] - row['kitch_sq']\n",
    "    return row['life_sq_help']\n",
    "    \n",
    "def fill_max_floor (row):\n",
    "    if not pd.isnull(row['build_year']) and row['build_year'] < 1930:\n",
    "        return 2\n",
    "    if not pd.isnull(row['max_floor']):\n",
    "        return row['max_floor']\n",
    "    if not pd.isnull(row['build_year']) and row['build_year'] > 0:\n",
    "        dict_year = (row['build_year'] // 10) * 10\n",
    "        if dict_year < 1930:\n",
    "            return 2\n",
    "        else:\n",
    "            return d[dict_year]\n",
    "    if not pd.isna(row['floor']):\n",
    "        if row['floor'] > 16:\n",
    "            return row['floor']\n",
    "        if row['floor'] > 12:\n",
    "            return 16\n",
    "        if row['floor'] > 8:\n",
    "            return 12\n",
    "    return 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtV-68dn3Vag"
   },
   "outputs": [],
   "source": [
    "def custom_pipeline(data_recieved, is_train=True, numeric_features=numeric_features, \\\n",
    "                    categorical_features=categorical_features):\n",
    "    data = data_recieved.copy()\n",
    "    \n",
    "    if is_train:\n",
    "        data.drop(data[data['full_sq'] > 1000].index, inplace=True)\n",
    "        data.drop(data[data['build_year'] > 2018].index, inplace=True)\n",
    "        data.drop(data[(data['full_sq'] == 0) & (data['life_sq'] == 0) & (data['kitch_sq'] == 0)].index, \\\n",
    "                  inplace=True)\n",
    "\n",
    "    mean_division_value = 0.67\n",
    "    \n",
    "    data['life_sq/full_sq'] = data['life_sq'] / (data['full_sq'] + 1)\n",
    "    data['life_sq/full_sq'].mask(np.isinf(data['life_sq/full_sq']), inplace=True)\n",
    "    data['life_sq/full_sq'].fillna(mean_division_value, inplace=True)\n",
    "\n",
    "    data.loc[data['life_sq'] > 200, 'life_sq'] = \\\n",
    "                                data[data['life_sq'] > 200].apply(lambda x: \\\n",
    "                                x['full_sq'] - x['kitch_sq'] if x['kitch_sq'] >= 0 else x['full_sq'], axis=1)\n",
    "\n",
    "    mean_value = data['life_sq/full_sq'].mean()\n",
    "    data['life_sq'] = data.apply(lambda x: x['life_sq'] if not pd.isnull(x['life_sq']) \\\n",
    "                                   else x['full_sq'] * mean_value, axis=1)\n",
    "    \n",
    "    data_help = data[['full_sq', 'life_sq', 'kitch_sq', 'life_sq/full_sq']].copy()\n",
    "    data_help['life_sq_help'] = data_help.apply(change_life_sq, axis=1)\n",
    "    data_help['full_sq_help'] = data_help.apply(change_full_sq, axis=1)\n",
    "    data_help['life_sq_help'] = data_help.apply(account_kitch_sq, axis=1)\n",
    "    data_help['life_sq_help'] = data_help.apply(lambda x: x['life_sq_help'] \\\n",
    "                            if not pd.isnull(x['life_sq_help']) else x['full_sq_help'] * mean_value, axis=1)\n",
    "    data[['full_sq', 'life_sq']] = data_help[['full_sq_help', 'life_sq_help']]\n",
    "    data.loc[data['life_sq/full_sq'] > 0.9, 'life_sq'] = \\\n",
    "                    data.loc[data['life_sq/full_sq'] > 0.9].apply(lambda x: x['full_sq'] * mean_value, axis=1)\n",
    "    \n",
    "    data.loc[:, 'life_sq'] = data.apply(lambda x: math.ceil(x['life_sq']), axis=1)\n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['kitch_sq'] = data.apply(lambda x: x['full_sq'] - x['life_sq'] , axis = 1)\n",
    "    data['life_sq/kitch_sq'] = (data['life_sq']) / (data['kitch_sq'] + 1)\n",
    "    \n",
    "    data_help = data[['kitch_sq', 'life_sq', 'full_sq', 'life_sq/kitch_sq', 'num_room']].copy()\n",
    "    data_help['life_sq_help'] = data_help.apply(lambda x: x['kitch_sq'] \\\n",
    "                                    if x['life_sq/kitch_sq'] < x['num_room'] * 1.3 else x['life_sq'], axis=1)\n",
    "    data_help['kitch_sq_help'] = data_help.apply(lambda x: x['life_sq'] \\\n",
    "                                    if x['life_sq/kitch_sq'] < x['num_room'] * 1.3 else x['kitch_sq'], axis=1)\n",
    "    data[['life_sq', 'kitch_sq']]= data_help[['life_sq_help', 'kitch_sq_help']]\n",
    "    \n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['life_sq/kitch_sq'] = (data['life_sq'] + 1) / (data['kitch_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['kitch_sq/life_sq'] = 1 / data['life_sq/kitch_sq']\n",
    "    \n",
    "    data.rename(columns={'kitch_sq' : 'other_sq'}, inplace=True)\n",
    "    \n",
    "    numeric_features = [feature if feature != 'kitch_sq' else 'other_sq' for feature in numeric_features]\n",
    "    \n",
    "    data.loc[:, 'full_sq'] = data.apply(lambda x: round(x['full_sq']), axis=1)\n",
    "    data.loc[:, 'life_sq'] = data.apply(lambda x: round(x['life_sq']), axis=1)\n",
    "    data.loc[:, 'other_sq'] = data.apply(lambda x: round(x['other_sq']), axis=1)\n",
    "    \n",
    "    data.drop(columns=['life_sq/kitch_sq', 'kitch_sq/life_sq'], inplace=True)\n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['life_sq/other_sq'] = (data['life_sq'] + 1) / (data['other_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['other_sq/life_sq'] = 1 / data['life_sq/other_sq']\n",
    "    \n",
    "    sample_data = data[['life_sq', 'other_sq', 'life_sq/other_sq']].copy()\n",
    "    data.loc[:, 'life_sq'] = sample_data.apply(lambda x: x['life_sq'] if \\\n",
    "                                        x['life_sq/other_sq'] > 0.8 else x['other_sq'], axis=1)\n",
    "    data.loc[:, 'other_sq'] = sample_data.apply(lambda x: x['other_sq'] if \\\n",
    "                                        x['life_sq/other_sq'] > 0.8 else x['life_sq'], axis=1)\n",
    "    \n",
    "    data['life_sq/full_sq'] = (data['life_sq'] + 1) / (data['full_sq'] + 1)\n",
    "    data['life_sq/other_sq'] = (data['life_sq'] + 1) / (data['other_sq'] + 1)\n",
    "    data['full_sq/life_sq'] = 1 / data['life_sq/full_sq']\n",
    "    data['other_sq/life_sq'] = 1 / data['life_sq/other_sq'] \n",
    "    \n",
    "    if is_train:\n",
    "        data.drop(data[data['full_sq'] > 290].index, inplace=True)\n",
    "        data.drop(1030, inplace=True)\n",
    "    \n",
    "    data.loc[:, 'max_floor'] = data.apply(lambda x: x['floor'] \\\n",
    "                                     if x['floor'] > x['max_floor'] else x['max_floor'], axis=1)\n",
    "    data.loc[:, 'max_floor'] = data.apply(fill_max_floor, axis=1)\n",
    "    data.loc[:, 'floor'] = data.apply(lambda x: x['max_floor'] // 2 if pd.isnull(x['floor']) \\\n",
    "                             else x['floor'], axis=1)\n",
    "    data.loc[data['build_year'] < 1860, 'build_year'] = np.nan\n",
    "    \n",
    "    data.loc[:, 'num_room was missing'] = data['num_room'].isnull()\n",
    "    data.loc[data['num_room'].isnull(), 'num_room'] = np.round(data.loc[data['num_room'].isnull(), \\\n",
    "                                                                       'life_sq'] / 23)\n",
    "    data.loc[:, 'material'].fillna(7, inplace=True)\n",
    "    \n",
    "    for feature in missed_features:\n",
    "        data[feature + ' was missing'] = data[feature].isnull()\n",
    "        for area in set(data['sub_area'].values):\n",
    "            if area in set(train['sub_area'].values):\n",
    "                data.loc[(data['sub_area'] == area) & (pd.isnull(data[feature])), feature] = \\\n",
    "                train[(train['sub_area'] == area) & (~pd.isnull(train[feature]))][feature].median()\n",
    "\n",
    "    data.loc[pd.isnull(data['product_type']), 'product_type'] = 'Investment'\n",
    "                \n",
    "    for column_name in data.columns:\n",
    "        data[column_name + ' was missing'] = data[column_name].isnull()\n",
    "    \n",
    "    if is_train:\n",
    "        my_label_encoder.fit(data['sub_area'])\n",
    "    data.loc[:, 'sub_area'] = my_label_encoder.transform(data['sub_area'])\n",
    "    \n",
    "    if is_train:\n",
    "        my_imputer.fit(data.loc[:, numeric_features[: -1]])\n",
    "    data.loc[:, numeric_features[: -1]] = my_imputer.transform(data.loc[:, numeric_features[: -1]])\n",
    "    \n",
    "    if is_train:\n",
    "        my_scaler.fit(data.loc[:, numeric_features[: -1]])\n",
    "    data.loc[:, numeric_features[:-1]] = my_scaler.transform(data.loc[:, numeric_features[: -1]])\n",
    "    \n",
    "    label_features = ['sub_area']\n",
    "    one_hot_features = categorical_features.copy()\n",
    "    \n",
    "    for feature in label_features:\n",
    "        one_hot_features.remove(feature)\n",
    "    \n",
    "    if is_train:\n",
    "        my_hot_encoder.fit(data.loc[:, one_hot_features])\n",
    "    \n",
    "    new_hot_features = pd.DataFrame(my_hot_encoder.transform(data.loc[:, one_hot_features]).toarray())\n",
    "    for column in new_hot_features.columns:\n",
    "        new_hot_features.rename(columns={column : 'One_hot_' + str(column)}, inplace=True)\n",
    "    data[new_hot_features.columns] = new_hot_features.set_index(data.index)\n",
    "    \n",
    "    data.drop(columns=one_hot_features, inplace=True)\n",
    "    \n",
    "    data['month'] = data.apply(lambda x: x['timestamp'].month, axis=1)\n",
    "    data['year'] = data.apply(lambda x: x['timestamp'].year, axis=1)\n",
    "    \n",
    "    data.drop(columns=['timestamp'], inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeCPRgWV5yf9"
   },
   "outputs": [],
   "source": [
    "new_train = custom_pipeline(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = custom_pipeline(test, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phqhDJiIl2al",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "investment_indexes = train[train['product_type'] == 'Investment'].index\n",
    "investment_indexes = [index for index in investment_indexes if index in new_train.index]\n",
    "owner_occupier_indexes = train[train['product_type'] != 'Investment'].index\n",
    "owner_occupier_indexes = [index for index in owner_occupier_indexes if index in new_train.index]\n",
    "new_train_investment = new_train.loc[investment_indexes, :]\n",
    "    new_train_investment_y = new_train_investment['price_doc']\n",
    "new_train_investment.drop(columns=['price_doc'], inplace=True)\n",
    "new_train_owner_occupier = new_train.loc[owner_occupier_indexes, :]\n",
    "new_train_owner_occupier_y = new_train_owner_occupier['price_doc']\n",
    "new_train_owner_occupier.drop(columns=['price_doc'], inplace=True)\n",
    "owner_occupier_indexes = test[test['product_type'] == 'OwnerOccupier'].index\n",
    "investment_indexes = test[test['product_type'] != 'OwnerOccupier'].index\n",
    "new_test_investment = new_test.loc[investment_indexes, :]\n",
    "new_test_owner_occupier = new_test.loc[owner_occupier_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1tTF_HQl2ap"
   },
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePBC_76_l2az"
   },
   "outputs": [],
   "source": [
    "investment_model = LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "                                  importance_type='split', learning_rate=0.0958080808080808,\n",
    "                                  max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
    "                                  min_split_gain=0.0, n_estimators=114, n_jobs=-1, num_leaves=21,\n",
    "                                  objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
    "                                  silent=True, subsample=1.0, subsample_for_bin=200000,\n",
    "                                  subsample_freq=0)\n",
    "owner_occupier_model = LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "                                  importance_type='split', learning_rate=0.0958080808080808,\n",
    "                                  max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
    "                                  min_split_gain=0.0, n_estimators=114, n_jobs=-1, num_leaves=21,\n",
    "                                  objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
    "                                  silent=True, subsample=1.0, subsample_for_bin=200000,\n",
    "                                  subsample_freq=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_RMSLE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))** 2))\n",
    "\n",
    "scorer = make_scorer(scorer_RMSLE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_feature_list = []\n",
    "\n",
    "prev_score = np.inf\n",
    "\n",
    "for i in range(2):\n",
    "    print('Phase', i + 1, 'started:')\n",
    "    print('---------------------')\n",
    "    for idx, feature in enumerate(new_train_investment.columns):\n",
    "        if feature in curr_feature_list:\n",
    "            continue\n",
    "        curr_feature_list.append(feature)\n",
    "        cur_score = np.mean(cross_val_score(investment_model, new_train_investment.loc[:, curr_feature_list], \\\n",
    "                            new_train_investment_y, scoring=scorer, cv=5, fit_params = {'eval_metric' : rmsle}))\n",
    "        if abs(cur_score) - prev_score < 0:\n",
    "            prev_score = abs(cur_score)\n",
    "        else:\n",
    "            curr_feature_list.pop()\n",
    "        if idx % 100 == 0:\n",
    "            print(idx, ' features considered out of', len(new_train_investment.columns))\n",
    "    print('Phase', i + 1, 'done!')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2 epochs to understand which features we take because some features can heavily rely on others and we wouldn't have taken them if we had only 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_feature_list = ['full_sq', 'life_sq', 'floor', 'max_floor', 'material', 'build_year', 'num_room',\\\n",
    "                     'state', 'sub_area', 'area_m', 'raion_popul', 'green_zone_part', 'indust_part',\\\n",
    "                     'children_preschool', 'preschool_quota', 'school_quota', 'hospital_beds_raion',\\\n",
    "                     'sport_objects_raion', 'office_raion', 'full_all', 'female_f', 'young_all',\\\n",
    "                     'raion_build_count_with_material_info', 'build_count_block', 'build_count_panel',\\\n",
    "                     'build_count_foam', 'build_count_1921-1945', 'ID_metro', 'metro_min_avto',\\\n",
    "                     'metro_min_walk', 'kindergarten_km', 'ID_railroad_station_avto', 'mkad_km',\\\n",
    "                     'ttk_km', 'kremlin_km', 'big_road2_km', 'railroad_km', 'zd_vokzaly_avto_km',\\\n",
    "                     'ID_railroad_terminal', 'bus_terminal_avto_km', 'oil_chemistry_km', 'ts_km',\\\n",
    "                     'detention_facility_km', 'mosque_km', 'office_count_500', 'cafe_count_500',\\\n",
    "                     'cafe_count_1000_price_high', 'sport_count_1000', 'trc_count_2000', 'trc_sqm_2000',\\\n",
    "                     'cafe_sum_2000_max_price_avg', 'mosque_count_3000', 'market_count_5000',\\\n",
    "                     'life_sq/other_sq', 'other_sq/life_sq', 'One_hot_0', 'One_hot_18', 'year',\\\n",
    "                     'school_education_centers_top_20_raion', 'build_count_mix', 'One_hot_14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(curr_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['full_sq',\n",
       " 'life_sq',\n",
       " 'floor',\n",
       " 'max_floor',\n",
       " 'material',\n",
       " 'build_year',\n",
       " 'num_room',\n",
       " 'state',\n",
       " 'sub_area',\n",
       " 'area_m',\n",
       " 'raion_popul',\n",
       " 'green_zone_part',\n",
       " 'indust_part',\n",
       " 'children_preschool',\n",
       " 'preschool_quota',\n",
       " 'school_quota',\n",
       " 'hospital_beds_raion',\n",
       " 'sport_objects_raion',\n",
       " 'office_raion',\n",
       " 'full_all',\n",
       " 'female_f',\n",
       " 'young_all',\n",
       " 'raion_build_count_with_material_info',\n",
       " 'build_count_block',\n",
       " 'build_count_panel',\n",
       " 'build_count_foam',\n",
       " 'build_count_1921-1945',\n",
       " 'ID_metro',\n",
       " 'metro_min_avto',\n",
       " 'metro_min_walk',\n",
       " 'kindergarten_km',\n",
       " 'ID_railroad_station_avto',\n",
       " 'mkad_km',\n",
       " 'ttk_km',\n",
       " 'kremlin_km',\n",
       " 'big_road2_km',\n",
       " 'railroad_km',\n",
       " 'zd_vokzaly_avto_km',\n",
       " 'ID_railroad_terminal',\n",
       " 'bus_terminal_avto_km',\n",
       " 'oil_chemistry_km',\n",
       " 'ts_km',\n",
       " 'detention_facility_km',\n",
       " 'mosque_km',\n",
       " 'office_count_500',\n",
       " 'cafe_count_500',\n",
       " 'cafe_count_1000_price_high',\n",
       " 'sport_count_1000',\n",
       " 'trc_count_2000',\n",
       " 'trc_sqm_2000',\n",
       " 'cafe_sum_2000_max_price_avg',\n",
       " 'mosque_count_3000',\n",
       " 'market_count_5000',\n",
       " 'life_sq/other_sq',\n",
       " 'other_sq/life_sq',\n",
       " 'One_hot_0',\n",
       " 'One_hot_18',\n",
       " 'year',\n",
       " 'school_education_centers_top_20_raion',\n",
       " 'build_count_mix',\n",
       " 'One_hot_14']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should remove year because we'll adjust prices later on and now the task is to evaluate the house as asset without looking at the date of the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_feature_list.remove('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively all the important features were taken, let's take a look at some of the other important features which were not taken. (from data dictionary and overall housing market knowledge we can say that the most important features are among 50 first, other features are mostely less important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_17_all',\n",
       " '0_17_female',\n",
       " '0_17_male',\n",
       " '0_6_all',\n",
       " '0_6_female',\n",
       " '0_6_male',\n",
       " '7_14_all',\n",
       " '7_14_female',\n",
       " '7_14_male',\n",
       " 'additional_education_raion',\n",
       " 'children_school',\n",
       " 'culture_objects_top_25_raion',\n",
       " 'ekder_all',\n",
       " 'ekder_female',\n",
       " 'ekder_male',\n",
       " 'healthcare_centers_raion',\n",
       " 'male_f',\n",
       " 'other_sq',\n",
       " 'preschool_education_centers_raion',\n",
       " 'school_education_centers_raion',\n",
       " 'shopping_centers_raion',\n",
       " 'university_top_20_raion',\n",
       " 'work_all',\n",
       " 'work_female',\n",
       " 'work_male',\n",
       " 'young_female',\n",
       " 'young_male'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_train_investment.iloc[:, :50].columns) - set(curr_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's strange that other_sq, university_top_20_raion, shopping_centers_raion, additional_education_raion,\n",
    "children_school, culture_objects_top_25_raion and healthcare_centers_raion were not taken! I'll add them manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_feature_list.append('other_sq')\n",
    "curr_feature_list.append('university_top_20_raion')\n",
    "curr_feature_list.append('shopping_centers_raion')\n",
    "curr_feature_list.append('additional_education_raion')\n",
    "curr_feature_list.append('children_school')\n",
    "curr_feature_list.append('culture_objects_top_25_raion')\n",
    "curr_feature_list.append('healthcare_centers_raion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personally I want to add One_hot_features because the won't really affect learning time but can benefit our model because these features seem important judging by data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in new_train_investment.columns:\n",
    "    if 'One_hot' in feature and feature not in curr_feature_list:\n",
    "        curr_feature_list.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(curr_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine remaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_13_all',\n",
       " '0_13_female',\n",
       " '0_13_male',\n",
       " '0_17_all',\n",
       " '0_17_female',\n",
       " '0_17_male',\n",
       " '0_6_all',\n",
       " '0_6_female',\n",
       " '0_6_male',\n",
       " '16_29_all',\n",
       " '16_29_female',\n",
       " '16_29_male',\n",
       " '7_14_all',\n",
       " '7_14_female',\n",
       " '7_14_male',\n",
       " 'ID_big_road1',\n",
       " 'ID_big_road2',\n",
       " 'ID_bus_terminal',\n",
       " 'ID_railroad_station_walk',\n",
       " 'additional_education_km',\n",
       " 'basketball_km',\n",
       " 'big_church_count_1000',\n",
       " 'big_church_count_1500',\n",
       " 'big_church_count_2000',\n",
       " 'big_church_count_3000',\n",
       " 'big_church_count_500',\n",
       " 'big_church_count_5000',\n",
       " 'big_church_km',\n",
       " 'big_market_km',\n",
       " 'big_road1_km',\n",
       " 'build_count_1946-1970',\n",
       " 'build_count_1971-1995',\n",
       " 'build_count_after_1995',\n",
       " 'build_count_before_1920',\n",
       " 'build_count_brick',\n",
       " 'build_count_frame',\n",
       " 'build_count_monolith',\n",
       " 'build_count_slag',\n",
       " 'build_count_wood',\n",
       " 'bulvar_ring_km',\n",
       " 'cafe_avg_price_1000',\n",
       " 'cafe_avg_price_1500',\n",
       " 'cafe_avg_price_2000',\n",
       " 'cafe_avg_price_3000',\n",
       " 'cafe_avg_price_500',\n",
       " 'cafe_avg_price_5000',\n",
       " 'cafe_count_1000',\n",
       " 'cafe_count_1000_na_price',\n",
       " 'cafe_count_1000_price_1000',\n",
       " 'cafe_count_1000_price_1500',\n",
       " 'cafe_count_1000_price_2500',\n",
       " 'cafe_count_1000_price_4000',\n",
       " 'cafe_count_1000_price_500',\n",
       " 'cafe_count_1500',\n",
       " 'cafe_count_1500_na_price',\n",
       " 'cafe_count_1500_price_1000',\n",
       " 'cafe_count_1500_price_1500',\n",
       " 'cafe_count_1500_price_2500',\n",
       " 'cafe_count_1500_price_4000',\n",
       " 'cafe_count_1500_price_500',\n",
       " 'cafe_count_1500_price_high',\n",
       " 'cafe_count_2000',\n",
       " 'cafe_count_2000_na_price',\n",
       " 'cafe_count_2000_price_1000',\n",
       " 'cafe_count_2000_price_1500',\n",
       " 'cafe_count_2000_price_2500',\n",
       " 'cafe_count_2000_price_4000',\n",
       " 'cafe_count_2000_price_500',\n",
       " 'cafe_count_2000_price_high',\n",
       " 'cafe_count_3000',\n",
       " 'cafe_count_3000_na_price',\n",
       " 'cafe_count_3000_price_1000',\n",
       " 'cafe_count_3000_price_1500',\n",
       " 'cafe_count_3000_price_2500',\n",
       " 'cafe_count_3000_price_4000',\n",
       " 'cafe_count_3000_price_500',\n",
       " 'cafe_count_3000_price_high',\n",
       " 'cafe_count_5000',\n",
       " 'cafe_count_5000_na_price',\n",
       " 'cafe_count_5000_price_1000',\n",
       " 'cafe_count_5000_price_1500',\n",
       " 'cafe_count_5000_price_2500',\n",
       " 'cafe_count_5000_price_4000',\n",
       " 'cafe_count_5000_price_500',\n",
       " 'cafe_count_5000_price_high',\n",
       " 'cafe_count_500_na_price',\n",
       " 'cafe_count_500_price_1000',\n",
       " 'cafe_count_500_price_1500',\n",
       " 'cafe_count_500_price_2500',\n",
       " 'cafe_count_500_price_4000',\n",
       " 'cafe_count_500_price_500',\n",
       " 'cafe_count_500_price_high',\n",
       " 'cafe_sum_1000_max_price_avg',\n",
       " 'cafe_sum_1000_min_price_avg',\n",
       " 'cafe_sum_1500_max_price_avg',\n",
       " 'cafe_sum_1500_min_price_avg',\n",
       " 'cafe_sum_2000_min_price_avg',\n",
       " 'cafe_sum_3000_max_price_avg',\n",
       " 'cafe_sum_3000_min_price_avg',\n",
       " 'cafe_sum_5000_max_price_avg',\n",
       " 'cafe_sum_5000_min_price_avg',\n",
       " 'cafe_sum_500_max_price_avg',\n",
       " 'cafe_sum_500_min_price_avg',\n",
       " 'catering_km',\n",
       " 'cemetery_km',\n",
       " 'church_count_1000',\n",
       " 'church_count_1500',\n",
       " 'church_count_2000',\n",
       " 'church_count_3000',\n",
       " 'church_count_500',\n",
       " 'church_count_5000',\n",
       " 'church_synagogue_km',\n",
       " 'ekder_all',\n",
       " 'ekder_female',\n",
       " 'ekder_male',\n",
       " 'exhibition_km',\n",
       " 'fitness_km',\n",
       " 'full_sq/life_sq',\n",
       " 'green_part_1000',\n",
       " 'green_part_1500',\n",
       " 'green_part_2000',\n",
       " 'green_part_3000',\n",
       " 'green_part_500',\n",
       " 'green_part_5000',\n",
       " 'green_zone_km',\n",
       " 'hospice_morgue_km',\n",
       " 'ice_rink_km',\n",
       " 'incineration_km',\n",
       " 'industrial_km',\n",
       " 'leisure_count_1000',\n",
       " 'leisure_count_1500',\n",
       " 'leisure_count_2000',\n",
       " 'leisure_count_3000',\n",
       " 'leisure_count_500',\n",
       " 'leisure_count_5000',\n",
       " 'life_sq/full_sq',\n",
       " 'male_f',\n",
       " 'market_count_1000',\n",
       " 'market_count_1500',\n",
       " 'market_count_2000',\n",
       " 'market_count_3000',\n",
       " 'market_count_500',\n",
       " 'market_shop_km',\n",
       " 'metro_km_avto',\n",
       " 'metro_km_walk',\n",
       " 'month',\n",
       " 'mosque_count_1000',\n",
       " 'mosque_count_1500',\n",
       " 'mosque_count_2000',\n",
       " 'mosque_count_500',\n",
       " 'mosque_count_5000',\n",
       " 'museum_km',\n",
       " 'nuclear_reactor_km',\n",
       " 'office_count_1000',\n",
       " 'office_count_1500',\n",
       " 'office_count_2000',\n",
       " 'office_count_3000',\n",
       " 'office_count_5000',\n",
       " 'office_km',\n",
       " 'office_sqm_1000',\n",
       " 'office_sqm_1500',\n",
       " 'office_sqm_2000',\n",
       " 'office_sqm_3000',\n",
       " 'office_sqm_500',\n",
       " 'office_sqm_5000',\n",
       " 'park_km',\n",
       " 'power_transmission_line_km',\n",
       " 'preschool_education_centers_raion',\n",
       " 'preschool_km',\n",
       " 'prom_part_1000',\n",
       " 'prom_part_1500',\n",
       " 'prom_part_2000',\n",
       " 'prom_part_3000',\n",
       " 'prom_part_500',\n",
       " 'prom_part_5000',\n",
       " 'public_healthcare_km',\n",
       " 'public_transport_station_km',\n",
       " 'public_transport_station_min_walk',\n",
       " 'radiation_km',\n",
       " 'railroad_station_avto_km',\n",
       " 'railroad_station_avto_min',\n",
       " 'railroad_station_walk_km',\n",
       " 'railroad_station_walk_min',\n",
       " 'raion_build_count_with_builddate_info',\n",
       " 'sadovoe_km',\n",
       " 'school_education_centers_raion',\n",
       " 'school_km',\n",
       " 'shopping_centers_km',\n",
       " 'sport_count_1500',\n",
       " 'sport_count_2000',\n",
       " 'sport_count_3000',\n",
       " 'sport_count_500',\n",
       " 'sport_count_5000',\n",
       " 'stadium_km',\n",
       " 'swim_pool_km',\n",
       " 'theater_km',\n",
       " 'thermal_power_plant_km',\n",
       " 'trc_count_1000',\n",
       " 'trc_count_1500',\n",
       " 'trc_count_3000',\n",
       " 'trc_count_500',\n",
       " 'trc_count_5000',\n",
       " 'trc_sqm_1000',\n",
       " 'trc_sqm_1500',\n",
       " 'trc_sqm_3000',\n",
       " 'trc_sqm_500',\n",
       " 'trc_sqm_5000',\n",
       " 'university_km',\n",
       " 'water_km',\n",
       " 'water_treatment_km',\n",
       " 'work_all',\n",
       " 'work_female',\n",
       " 'work_male',\n",
       " 'workplaces_km',\n",
       " 'year',\n",
       " 'young_female',\n",
       " 'young_male'}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([a for a in new_train_investment.columns if 'was missing' not in a]) - set(curr_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the features I either found helpful or which complement features taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_feature_list.append('additional_education_km')\n",
    "curr_feature_list.append('big_church_km')\n",
    "curr_feature_list.append('big_market_km')\n",
    "curr_feature_list.append('big_road1_km')\n",
    "curr_feature_list.append('bulvar_ring_km')\n",
    "curr_feature_list.append('church_synagogue_km')\n",
    "curr_feature_list.append('fitness_km')\n",
    "curr_feature_list.append('full_sq/life_sq')\n",
    "curr_feature_list.append('green_zone_km')\n",
    "curr_feature_list.append('ice_rink_km')\n",
    "curr_feature_list.append('park_km')\n",
    "curr_feature_list.append('public_healthcare_km')\n",
    "curr_feature_list.append('public_transport_station_min_walk')\n",
    "curr_feature_list.append('railroad_station_walk_min')\n",
    "curr_feature_list.append('sadovoe_km')\n",
    "curr_feature_list.append('school_km')\n",
    "curr_feature_list.append('shopping_centers_km')\n",
    "curr_feature_list.append('university_km')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's drop unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_score = np.inf\n",
    "\n",
    "for i in range(2):\n",
    "    total_phases = len(curr_feature_list )\n",
    "    print('Phase', i + 1, 'started:')\n",
    "    print('---------------------')\n",
    "    total_phases = len(curr_feature_list )\n",
    "    for idx, feature in enumerate(curr_feature_list ):\n",
    "        if idx % 100 == 0:\n",
    "            print(idx, ' features considered out of', total_phases)\n",
    "        curr_feature_list.remove(feature)\n",
    "        cur_score = np.mean(cross_val_score(investment_model, new_train_investment.loc[:, curr_feature_list], \\\n",
    "                            new_train_investment_y, scoring=scorer, cv=5, fit_params = {'eval_metric' : rmsle}))\n",
    "        if abs(cur_score) - prev_score < 0:\n",
    "            prev_score = abs(cur_score)\n",
    "            print(feature, 'dropped out')\n",
    "        else:\n",
    "            curr_feature_list.insert(idx, feature)\n",
    "    print('Phase', i + 1, 'done!')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_feature_list.remove('max_floor')\n",
    "curr_feature_list.remove('area_m')\n",
    "curr_feature_list.remove('preschool_quota')\n",
    "curr_feature_list.remove('raion_build_count_with_material_info')\n",
    "curr_feature_list.remove('build_count_mix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(curr_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe that preschool_quota is an important feature a thus I want to understand whether this feature is bad or it was dropped due to conjuncture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_feature_list.append('preschool_quota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prev_score -0.5787638004133642\n",
      "Cur_score -0.5783484139975001\n"
     ]
    }
   ],
   "source": [
    "prev_score = np.array([])\n",
    "for i in range (10):\n",
    "    prev_score = np.append(prev_score, np.mean(cross_val_score(investment_model, \\\n",
    "                           new_train_investment.loc[:, curr_feature_list], new_train_investment_y, \\\n",
    "                           scoring=scorer, cv=5, fit_params = {'eval_metric' : rmsle})))\n",
    "prev_score = np.mean(prev_score)\n",
    "curr_feature_list.pop()\n",
    "curr_score = np.array([])\n",
    "for i in range (10):\n",
    "    curr_score = np.append(prev_score, np.mean(cross_val_score(investment_model, \\\n",
    "                           new_train_investment.loc[:, curr_feature_list], new_train_investment_y, \\\n",
    "                           scoring=scorer, cv=5, fit_params = {'eval_metric' : rmsle})))\n",
    "cur_score = np.mean(cur_score)\n",
    "print('Prev_score', prev_score)\n",
    "print('Cur_score', cur_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00041538641586402747"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(cur_score) - abs(prev_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that this feature is decreasing our performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make new features from the ones we didn't take with the assistance of TSNE and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_taken_features = list(set(new_train_investment.columns) - set(curr_feature_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_new_train = pd.concat([new_train_investment, new_train_owner_occupier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_PCA = PCA(n_components=10, random_state=1)\n",
    "new_coord_PCA = my_PCA.fit_transform(full_new_train.loc[:, not_taken_features])\n",
    "my_PCA_scaler = StandardScaler()\n",
    "new_coord_PCA = my_PCA_scaler.fit_transform(new_coord_PCA)\n",
    "new_coord_PCA = pd.DataFrame(new_coord_PCA)\n",
    "for column in new_coord_PCA.columns:\n",
    "    new_coord_PCA.rename(columns={column : 'PCA_' + str(column)}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_new_train[new_coord_PCA.columns] = new_coord_PCA.set_index(full_new_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 started:\n",
      "---------------------\n",
      "PCA_0 dropped out\n",
      "PCA_6 dropped out\n",
      "Phase 1 done!\n",
      "\n",
      "Phase 2 started:\n",
      "---------------------\n",
      "PCA_5 dropped out\n",
      "Phase 2 done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev_score = np.inf\n",
    "\n",
    "curr_PCA_feature_list = list(new_coord_PCA.columns)\n",
    "for i in range(2):\n",
    "    print('Phase', i + 1, 'started:')\n",
    "    print('---------------------')\n",
    "    for idx, feature in enumerate(curr_PCA_feature_list):\n",
    "        curr_PCA_feature_list.remove(feature)\n",
    "        cur_score = np.mean(cross_val_score(investment_model, full_new_train.loc[:, \\\n",
    "                            curr_feature_list + curr_PCA_feature_list], \\\n",
    "                            pd.concat([new_train_investment_y, new_train_owner_occupier_y]), \n",
    "                            scoring=scorer, cv=5, fit_params = {'eval_metric' : rmsle}))\n",
    "        if abs(cur_score) - prev_score < 0:\n",
    "            prev_score = abs(cur_score)\n",
    "            print(feature, 'dropped out')\n",
    "        else:\n",
    "            curr_PCA_feature_list.insert(idx, feature)\n",
    "    print('Phase', i + 1, 'done!')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_feature_list += curr_PCA_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['life_sq',\n",
       " 'floor',\n",
       " 'material',\n",
       " 'build_year',\n",
       " 'num_room',\n",
       " 'state',\n",
       " 'sub_area',\n",
       " 'raion_popul',\n",
       " 'green_zone_part',\n",
       " 'indust_part',\n",
       " 'children_preschool',\n",
       " 'school_quota',\n",
       " 'hospital_beds_raion',\n",
       " 'sport_objects_raion',\n",
       " 'office_raion',\n",
       " 'full_all',\n",
       " 'female_f',\n",
       " 'young_all',\n",
       " 'build_count_block',\n",
       " 'build_count_panel',\n",
       " 'build_count_foam',\n",
       " 'build_count_1921-1945',\n",
       " 'ID_metro',\n",
       " 'metro_min_avto',\n",
       " 'metro_min_walk',\n",
       " 'kindergarten_km',\n",
       " 'ID_railroad_station_avto',\n",
       " 'mkad_km',\n",
       " 'ttk_km',\n",
       " 'kremlin_km',\n",
       " 'big_road2_km',\n",
       " 'railroad_km',\n",
       " 'zd_vokzaly_avto_km',\n",
       " 'ID_railroad_terminal',\n",
       " 'bus_terminal_avto_km',\n",
       " 'oil_chemistry_km',\n",
       " 'ts_km',\n",
       " 'detention_facility_km',\n",
       " 'mosque_km',\n",
       " 'office_count_500',\n",
       " 'cafe_count_500',\n",
       " 'cafe_count_1000_price_high',\n",
       " 'sport_count_1000',\n",
       " 'trc_count_2000',\n",
       " 'trc_sqm_2000',\n",
       " 'cafe_sum_2000_max_price_avg',\n",
       " 'mosque_count_3000',\n",
       " 'market_count_5000',\n",
       " 'life_sq/other_sq',\n",
       " 'other_sq/life_sq',\n",
       " 'One_hot_0',\n",
       " 'One_hot_18',\n",
       " 'school_education_centers_top_20_raion',\n",
       " 'One_hot_14',\n",
       " 'other_sq',\n",
       " 'university_top_20_raion',\n",
       " 'shopping_centers_raion',\n",
       " 'additional_education_raion',\n",
       " 'children_school',\n",
       " 'culture_objects_top_25_raion',\n",
       " 'healthcare_centers_raion',\n",
       " 'One_hot_1',\n",
       " 'One_hot_2',\n",
       " 'One_hot_3',\n",
       " 'One_hot_4',\n",
       " 'One_hot_5',\n",
       " 'One_hot_6',\n",
       " 'One_hot_7',\n",
       " 'One_hot_8',\n",
       " 'One_hot_9',\n",
       " 'One_hot_10',\n",
       " 'One_hot_11',\n",
       " 'One_hot_12',\n",
       " 'One_hot_13',\n",
       " 'One_hot_15',\n",
       " 'One_hot_16',\n",
       " 'One_hot_17',\n",
       " 'One_hot_19',\n",
       " 'One_hot_20',\n",
       " 'One_hot_21',\n",
       " 'One_hot_22',\n",
       " 'One_hot_23',\n",
       " 'One_hot_24',\n",
       " 'One_hot_25',\n",
       " 'One_hot_26',\n",
       " 'One_hot_27',\n",
       " 'One_hot_28',\n",
       " 'One_hot_29',\n",
       " 'One_hot_30',\n",
       " 'additional_education_km',\n",
       " 'big_church_km',\n",
       " 'big_market_km',\n",
       " 'big_road1_km',\n",
       " 'bulvar_ring_km',\n",
       " 'church_synagogue_km',\n",
       " 'fitness_km',\n",
       " 'full_sq/life_sq',\n",
       " 'green_zone_km',\n",
       " 'ice_rink_km',\n",
       " 'park_km',\n",
       " 'public_healthcare_km',\n",
       " 'public_transport_station_min_walk',\n",
       " 'railroad_station_walk_min',\n",
       " 'sadovoe_km',\n",
       " 'school_km',\n",
       " 'shopping_centers_km',\n",
       " 'university_km',\n",
       " 'PCA_1',\n",
       " 'PCA_2',\n",
       " 'PCA_3',\n",
       " 'PCA_4',\n",
       " 'PCA_7',\n",
       " 'PCA_8',\n",
       " 'PCA_9']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_feature_list"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Additional Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
